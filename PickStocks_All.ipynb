{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if 'COLAB_GPU' in os.environ:\n",
    "    !git clone https://github.com/impulsecorp/PickStocks.git\n",
    "    !mv PickStocks/*.py .\n",
    "    !mv PickStocks/data .\n",
    "    !pip install -U -qq -r PickStocks/requirements.txt\n",
    "    !pip install -qq autogluon\n",
    "    !pip install Pillow==9.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import system\n",
    "from system import *\n",
    "# small hack to prevent Colab error\n",
    "try:\n",
    "    from datablock import *\n",
    "except:\n",
    "    from datablock import *\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_timeperiod = 'D'\n",
    "data = get_data('SPY', period=data_timeperiod, nrows=None)\n",
    "data = procdata_lite(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for inspectiion\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system.train_set_end = 0.75 # percentage point specifying the training set end point (1.0 means all data is training set)\n",
    "system.val_set_end = 1.0 # percentage point specifying the validation set end point (1.0 means no test set)\n",
    "system.balance_data = 1\n",
    "system.scale_data = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train classifier on train data\n",
    "clf, scaler = train_classifier(LogisticRegression, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equity, pf, trades = qbacktest(clf, scaler, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trades.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train XGBClassifier classifier on train data\n",
    "clf, scaler = train_classifier(XGBClassifier, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on val data\n",
    "equity, pf, trades = qbacktest(clf, scaler, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trades.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LGBMClassifier classifier on train data\n",
    "clf, scaler = train_classifier(LGBMClassifier, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on val data\n",
    "equity, pf, trades = qbacktest(clf, scaler, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trades.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train RandomForestClassifier classifier on train data\n",
    "clf, scaler = train_classifier(RandomForestClassifier, data, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on val data\n",
    "equity, pf, trades = qbacktest(clf, scaler, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trades.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBClassifier + HPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train XGBClassifier classifier on train data, but optimize it with HPO first\n",
    "X_train, y_train = get_clean_Xy(data.iloc[0:int(data.shape[0] * system.train_set_end)])\n",
    "scaler = StandardScaler()\n",
    "if system.scale_data:\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "if system.balance_data:\n",
    "    # Apply SMOTE oversampling to balance the training data\n",
    "    sm = SMOTE(random_state=newseed())\n",
    "    X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "best_hyperparams = optimize_model(XGBClassifier(), 'XGBClassifier',\n",
    "                                  {\n",
    "                                        \"max_depth\": hp.quniform(\"max_depth\", 2, 12, 1),\n",
    "                                        \"learning_rate\": hp.uniform(\"learning_rate\", 0.001, 0.2),\n",
    "                                        \"n_estimators\": hp.quniform(\"n_estimators\", 5, 1000, 1),\n",
    "                                        \"min_child_weight\": hp.quniform(\"min_child_weight\", 1, 10, 1),\n",
    "                                        \"gamma\": hp.uniform(\"gamma\", 0, 1),\n",
    "                                        \"subsample\": hp.uniform(\"subsample\", 0.1, 1),\n",
    "                                        \"colsample_bytree\": hp.uniform(\"colsample_bytree\", 0.1, 1),\n",
    "                                        \"reg_alpha\": hp.uniform(\"reg_alpha\", 0, 1),\n",
    "                                        \"reg_lambda\": hp.uniform(\"reg_lambda\", 0, 1),\n",
    "                                  },\n",
    "                                  X_train, y_train, max_evals=10)\n",
    "clf, scaler = train_classifier(XGBClassifier, data, **best_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on val data\n",
    "equity, pf, trades = qbacktest(clf, scaler, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trades.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LogisticRegression ensemble on train data\n",
    "clf, scaler = train_clf_ensemble(LogisticRegression, data, ensemble_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on val data\n",
    "equity, pf, trades = qbacktest(clf, scaler, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trades.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoGluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train AutoGluon on train data\n",
    "X_train, y_train = get_clean_Xy(data.iloc[0:int(data.shape[0] * system.train_set_end)])\n",
    "scaler = StandardScaler()\n",
    "if system.scale_data:\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "if system.balance_data:\n",
    "    # Apply SMOTE oversampling to balance the training data\n",
    "    sm = SMOTE(random_state=newseed())\n",
    "    X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "xtd = pd.DataFrame(X_train)\n",
    "xtd['target'] = y_train\n",
    "clf = TabularPredictor(label='target').fit(xtd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on val data\n",
    "equity, pf, trades = qbacktest(clf, scaler, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trades.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = get_clean_Xy(data.iloc[0:int(data.shape[0] * system.train_set_end)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf, scaler = train_classifier(PyTorchClassifierWrapper, data, input_dim=X_train.shape[1], hidden_dim=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on val data\n",
    "equity, pf, trades = qbacktest(clf, scaler, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trades.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Big Move - search for best threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system.train_set_end = 0.5 # percentage point specifying the training set end point (1.0 means all data is training set)\n",
    "system.val_set_end = 0.75 # percentage point specifying the validation set end point (1.0 means no test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train classifier on train data\n",
    "clf, scaler = train_classifier(LogisticRegression, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equity, pf, trades = qbacktest(clf, scaler, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name = 'last move'\n",
    "\n",
    "# Compute the profit factor for every candidate value\n",
    "levels = np.linspace(0.0, 5.0, 100)\n",
    "pfs = []\n",
    "nts = []\n",
    "for l in tqdm(levels):\n",
    "    pf, ntrades = compute_stats(data, filter_trades_by_feature(trades, data, featformat(feature_name), min_value=l, use_abs=True))\n",
    "    pfs.append(pf)\n",
    "    nts.append(len(ntrades))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the optimization/search results\n",
    "plt.plot(levels, pfs);\n",
    "plt.xlabel(feature_name);\n",
    "plt.ylabel('Profit Factor');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(data = np.hstack([ np.array(nts).reshape(-1,1),\n",
    "                                      np.array(pfs).reshape(-1,1)]),\n",
    "             index=np.array(levels),\n",
    "             columns=['num trades', 'profit factor'])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_min_move = 1.0\n",
    "best_max_move = 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base test without the filter\n",
    "equity, pf, trades = qbacktest(clf, scaler, data, skip_val=1, skip_test=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with the filter\n",
    "equity, pf, trades = qbacktest(clf, scaler, data, quiet=1, skip_val=1, skip_test=0)\n",
    "# filter stats\n",
    "pf, ntrades = compute_stats(data, filter_trades_by_feature(trades, data, featformat(feature_name), min_value=best_min_move,\n",
    "                                                           max_value=best_max_move,\n",
    "                                                           use_abs=True))\n",
    "print(f'Profit factor: {get_profit_factor(ntrades):.5f}, Winners: {get_winner_pct(ntrades):.2f}%, Trades: {len(ntrades)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(ntrades['profit'].cumsum());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrades[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day Of Week - Search for best day of week to trade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system.train_set_end = 0.5 # percentage point specifying the training set end point (1.0 means all data is training set)\n",
    "system.val_set_end = 0.75 # percentage point specifying the validation set end point (1.0 means no test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train classifier on train data\n",
    "clf, scaler = train_classifier(LogisticRegression, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equity, pf, trades = qbacktest(clf, scaler, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name = 'day'\n",
    "\n",
    "# Compute the profit factor for every candidate value\n",
    "levels = [0,1,2,3,4]\n",
    "pfs = []\n",
    "nts = []\n",
    "for l in tqdm(levels):\n",
    "    pf, ntrades = compute_stats(data, filter_trades_by_feature(trades, data, featformat(feature_name), exact_value=l))\n",
    "    pfs.append(pf)\n",
    "    nts.append(len(ntrades))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the optimization/search results\n",
    "plt.plot(levels, pfs);\n",
    "plt.xlabel(feature_name);\n",
    "plt.ylabel('Profit Factor');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(data = np.hstack([ np.array(nts).reshape(-1,1),\n",
    "                                      np.array(pfs).reshape(-1,1)]),\n",
    "             index=np.array(levels),\n",
    "             columns=['num trades', 'profit factor'])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_day = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base test without the filter\n",
    "equity, pf, trades = qbacktest(clf, scaler, data, skip_val=1, skip_test=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with the filter\n",
    "equity, pf, trades = qbacktest(clf, scaler, data, quiet=1, skip_val=1, skip_test=0)\n",
    "# filter stats\n",
    "pf, ntrades = compute_stats(data, filter_trades_by_feature(trades, data, featformat(feature_name), exact_value=best_day))\n",
    "print(f'Profit factor: {get_profit_factor(ntrades):.5f}, Winners: {get_winner_pct(ntrades):.2f}%, Trades: {len(ntrades)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(ntrades['profit'].cumsum());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrades[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system.train_set_end = 0.5 # percentage point specifying the training set end point (1.0 means all data is training set)\n",
    "system.val_set_end = 0.75 # percentage point specifying the validation set end point (1.0 means no test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train classifier on train data\n",
    "clf, scaler = train_classifier(LogisticRegression, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equity, pf, trades = qbacktest(clf, scaler, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = [featdeformat(x) for x in data.filter(like='X')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_ranges = []\n",
    "for fn in feature_names:\n",
    "    d = data[featformat(fn)].values\n",
    "    feature_ranges.append((np.min(d), np.max(d)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bins for each feature\n",
    "num_bins = 10 + 1\n",
    "feat_bins = []\n",
    "for fmin, fmax in feature_ranges:\n",
    "    feat_bins.append(np.linspace(fmin, fmax, num_bins))\n",
    "feat_bins = np.array(feat_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train classifier on train data\n",
    "clf, scaler = train_classifier(LogisticRegression, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equity, pf, base_trades = qbacktest(clf, scaler, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_trades.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search for the best bins for each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_matrix = []\n",
    "nt_matrix = []\n",
    "wn_matrix = []\n",
    "\n",
    "coords = []\n",
    "\n",
    "for row_idx, (fname, bins) in enumerate(zip(tqdm(feature_names), feat_bins)):\n",
    "    pfs = []\n",
    "    nts = []\n",
    "    wns = []\n",
    "    for col_idx in range(1,len(bins)):\n",
    "        if bins[col_idx-1] > bins[col_idx]:\n",
    "            bs = bins[col_idx], bins[col_idx-1]\n",
    "        else:\n",
    "            bs = bins[col_idx-1], bins[col_idx]\n",
    "        pf, ntrades = compute_stats(data, filter_trades_by_feature(base_trades, data, featformat(fname), min_value=bs[0], max_value=bs[1]))\n",
    "        if (pf != -1) and (len(ntrades) > 0):\n",
    "            pf_matrix.append(pf)\n",
    "            nt_matrix.append(len(ntrades))\n",
    "            wn_matrix.append(get_winner_pct(ntrades))\n",
    "            coords.append((row_idx, col_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the PF matrix, take the top N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zpd = sorted(list(zip(pf_matrix, nt_matrix, wn_matrix, coords)), key = lambda x: x[2], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "min_pf = 1.0\n",
    "min_trades = 50\n",
    "max_trades = 1000\n",
    "# the top N PFs here\n",
    "top_pfs = []\n",
    "top_nts = []\n",
    "top_wns = []\n",
    "top_coords = []\n",
    "for pf, nt, wn, coords in zpd:\n",
    "    if (nt >= min_trades) and (nt <= max_trades) and (pf >= min_pf):\n",
    "        top_pfs.append(pf)\n",
    "        top_nts.append(nt)\n",
    "        top_wns.append(wn)\n",
    "        top_coords.append( coords )\n",
    "        if len(top_coords) >= N:\n",
    "            break\n",
    "pd.DataFrame(data=list(zip(top_pfs, top_nts, top_wns)), columns=['PF', 'Trades', ' % Winners'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description of the discovered best bins - the feature names and the bin boundaries\n",
    "for i in range(len(top_pfs)):\n",
    "    r,c = top_coords[i]\n",
    "    _, ntrades = compute_stats(data, filter_trades_by_feature(base_trades, data, featformat(feature_names[r]), min_value=feat_bins[r,c-1], max_value=feat_bins[r,c]))\n",
    "    print(feature_names[r], f'[{feat_bins[r,c-1]:.5f} .. {feat_bins[r,c]:.5f}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine all good strategies with OR into one big strategy and check the performance on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is done by simply merging all trade lists and then removing the duplicate trades\n",
    "alltrades = []\n",
    "for i in range(len(top_pfs)):\n",
    "    r,c = top_coords[i]\n",
    "    _, mtrades = compute_stats(data, filter_trades_by_feature(base_trades, data, featformat(feature_names[r]), min_value=feat_bins[r][c-1], max_value=feat_bins[r][c]))\n",
    "    alltrades.append(mtrades)\n",
    "alltrades = pd.concat(alltrades, axis=0).drop_duplicates().sort_index()\n",
    "plt.plot(alltrades['profit'].cumsum());\n",
    "print(f'Profit factor: {get_profit_factor(alltrades):.5f}, Winners: {get_winner_pct(alltrades):.2f}%, Trades: {len(alltrades)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alltrades.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base test without the filter\n",
    "clf, scaler = train_classifier(LogisticRegression, data)\n",
    "equity, _, test_trades = qbacktest(clf, scaler, data, skip_val=1, skip_test=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with the filter\n",
    "alltrades = []\n",
    "for r,c in top_coords:\n",
    "    _, mtrades = compute_stats(data, filter_trades_by_feature(test_trades, data, featformat(feature_names[r]), min_value=feat_bins[r,c-1], max_value=feat_bins[r,c]))\n",
    "    alltrades.append(mtrades)\n",
    "alltrades = pd.concat(alltrades, axis=0).drop_duplicates().sort_index()\n",
    "plt.plot(alltrades['profit'].cumsum());\n",
    "print(f'Profit factor: {get_profit_factor(alltrades):.5f}, Winners: {get_winner_pct(alltrades):.2f}%, Trades: {len(alltrades)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alltrades[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pred Prob - Search for best min_confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system.train_set_end = 0.5 # percentage point specifying the training set end point (1.0 means all data is training set)\n",
    "system.val_set_end = 0.75 # percentage point specifying the validation set end point (1.0 means no test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LogisticRegression ensemble on train data\n",
    "clf, scaler = train_clf_ensemble(LogisticRegression, data, ensemble_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equity, pf, trades = qbacktest(clf, scaler, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_conf_seen = np.max(np.abs(0.5-trades['pred'].values)*2.0)\n",
    "max_conf_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the profit factor for every candidate value\n",
    "levels = np.linspace(0.0, max_conf_seen, 100)\n",
    "pfs = []\n",
    "nts = []\n",
    "for l in tqdm(levels):\n",
    "    pf, ntrades = compute_stats(data, filter_trades_by_confidence(trades, min_conf=l))\n",
    "    pfs.append(pf)\n",
    "    nts.append(len(ntrades))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the optimization/search results\n",
    "plt.plot(levels, pfs);\n",
    "plt.xlabel('Confidence');\n",
    "plt.ylabel('Profit Factor');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(data = np.hstack([ np.array(nts).reshape(-1,1),\n",
    "                                      np.array(pfs).reshape(-1,1)]),\n",
    "             index=np.array(levels),\n",
    "             columns=['num trades', 'profit factor'])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_min_confidence = 0.15\n",
    "best_max_confidence = 0.35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base test without the filter\n",
    "clf, scaler = train_classifier(LogisticRegression, data)\n",
    "equity, pf, trades = qbacktest(clf, scaler, data, skip_val=1, skip_test=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with the filter\n",
    "# filter stats\n",
    "pf, ntrades = compute_stats(data, filter_trades_by_confidence(trades, min_conf=best_min_confidence, max_conf=best_max_confidence))\n",
    "print(f'Profit factor: {get_profit_factor(ntrades):.5f}, Winners: {get_winner_pct(ntrades):.2f}%, Trades: {len(ntrades)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(ntrades['profit'].cumsum());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrades[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X in row - Search for best value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system.train_set_end = 0.5 # percentage point specifying the training set end point (1.0 means all data is training set)\n",
    "system.val_set_end = 0.75 # percentage point specifying the validation set end point (1.0 means no test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name = 'times in row'\n",
    "# Compute the profit factor for every candidate value\n",
    "levels = [0,1,2,3,4,5,6,7,8,9,10]\n",
    "pfs = []\n",
    "nts = []\n",
    "for l in tqdm(levels):\n",
    "    pf, ntrades = compute_stats(data, filter_trades_by_feature(trades, data, featformat(feature_name), exact_value=l))\n",
    "    pfs.append(pf)\n",
    "    nts.append(len(ntrades))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the optimization/search results\n",
    "plt.plot(levels, pfs);\n",
    "plt.xlabel(feature_name);\n",
    "plt.ylabel('Profit Factor');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(data = np.hstack([ np.array(nts).reshape(-1,1),\n",
    "                                      np.array(pfs).reshape(-1,1)]),\n",
    "             index=np.array(levels),\n",
    "             columns=['num trades', 'profit factor'])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_best_x = 7\n",
    "max_best_x = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base test without the filter\n",
    "equity, pf, trades = qbacktest(clf, scaler, data, skip_val=1, skip_test=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with the filter\n",
    "equity, pf, trades = qbacktest(clf, scaler, data, quiet=1, skip_val=1, skip_test=0)\n",
    "# filter stats\n",
    "pf, ntrades = compute_stats(data, filter_trades_by_feature(trades, data, featformat(feature_name), min_value=min_best_x, max_value=max_best_x))\n",
    "print(f'Profit factor: {get_profit_factor(ntrades):.5f}, Winners: {get_winner_pct(ntrades):.2f}%, Trades: {len(ntrades)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(ntrades['profit'].cumsum());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrades[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4P1hkn83IWBY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bXPS0_S6IWDe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FMVxfFgHIWFm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KgAfHRr3IWHe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ahfyNn-bIWJW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d-fDcmjBIWQb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0VPOfZGMIWSv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01778ee7170742c1abe0d00a0f20c908": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1dcc1befa57743b39ea3c7572a63e0ba": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3986471ba62648cabf65cc14a3757d6f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4848583e7d8b41bd8b3c89609a0c92c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "520310df01c543c09c544177e9c4cf5e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_01778ee7170742c1abe0d00a0f20c908",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d3d46cf173434b47b79a7a5989b43926",
      "value": 0
     }
    },
    "5753c24721a544c1bf2ba8ea419308bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_89d408c0ddc443869be17d1a3233f10d",
      "placeholder": "​",
      "style": "IPY_MODEL_7278b7b0a08949d9a688f624cbf6fdca",
      "value": " 0/2 [00:00&lt;?, ?it/s]"
     }
    },
    "6354ff13a9af49a191d85b1253712d1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_aeae9f66c2c643e5929e148ae5054b55",
       "IPY_MODEL_520310df01c543c09c544177e9c4cf5e",
       "IPY_MODEL_5753c24721a544c1bf2ba8ea419308bc"
      ],
      "layout": "IPY_MODEL_1dcc1befa57743b39ea3c7572a63e0ba"
     }
    },
    "7278b7b0a08949d9a688f624cbf6fdca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "89d408c0ddc443869be17d1a3233f10d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aeae9f66c2c643e5929e148ae5054b55": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3986471ba62648cabf65cc14a3757d6f",
      "placeholder": "​",
      "style": "IPY_MODEL_4848583e7d8b41bd8b3c89609a0c92c6",
      "value": "Backtest.optimize:   0%"
     }
    },
    "d3d46cf173434b47b79a7a5989b43926": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
